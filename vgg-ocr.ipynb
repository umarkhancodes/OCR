{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, MaxPool2D\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow.keras import backend as K\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alphabet = {'0':0,'1':1,'2':2,'3':3,'4':4,'5':5,'6':6,'7':7,'8':8,'9':9,\n",
    "            'A':10,'B':11,'C':12,'D':13,\n",
    "            'E':14,'F':15,'G':16,'H':17\n",
    "            ,'I':18,'J':19,'K':20,'L':21,\n",
    "            'M':22,'N':23,'O':24,'P':25,\n",
    "            'Q':26,'R':27,'S':28,'T':29,\n",
    "            'U':30,'V':31,'W':32,\n",
    "            'X':33,'Y':34,'Z':35}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed for transformation of character to number.\n",
    "def char_to_num(char):\n",
    "    num = alphabet[char]\n",
    "    return num\n",
    "\n",
    "\n",
    "# Needed for transformation of number to character.\n",
    "def num_to_char(num):\n",
    "    for key in alphabet:\n",
    "        if alphabet[key] == num:\n",
    "            return key\n",
    "\n",
    "\n",
    "# Load file paths and labels them.\n",
    "def load_chars74k_data(dir=\"Binary\"):  #chars74k-complete\n",
    "    filenames = []\n",
    "    label_list = []\n",
    "\n",
    "    for path, dirs, files in os.walk(dir):\n",
    "        for file in files:\n",
    "            if file.endswith('.png'): #.jpg for chars#74 lite\n",
    "                file = path + '/' + file\n",
    "                filenames.append(file)\n",
    "\n",
    "                label = path[-1:]\n",
    "                label_list.append(label)\n",
    "\n",
    "    return filenames, label_list\n",
    "\n",
    "\n",
    "# Creates the dataset.\n",
    "def create_dataset(file_paths, label_set, with_denoising=False):\n",
    "    data_x = []\n",
    "    data_y = []\n",
    "\n",
    "    for path in file_paths:\n",
    "        #single_x = np.asarray((PIL.Image.open(path).convert('L')).resize((20,20))).flatten()\n",
    "        single_x = np.asarray((PIL.Image.open(path).convert('L')))\n",
    "        x=single_x.shape[0]\n",
    "        y=single_x.shape[1]\n",
    "        if x>y:\n",
    "            z=np.zeros((x,x))\n",
    "            z[0:x,0:y]=single_x\n",
    "        else:\n",
    "            z=np.zeros((y,y))\n",
    "            z[0:x,0:y]=single_x\n",
    "        single_x=(cv2.resize(z,(64,64))).flatten()\n",
    "        \n",
    "        # Denoise image with help of OpenCV (increase time of computing).\n",
    "        if with_denoising:\n",
    "            single_x = cv2.fastNlMeansDenoising(single_x).flatten()\n",
    "        data_x.append(single_x)\n",
    "\n",
    "    for l in label_set:\n",
    "        l_to_num = char_to_num(l)\n",
    "        data_y.append(l_to_num)\n",
    "\n",
    "    np_data_x = np.array(data_x)\n",
    "    np_data_y = np.array(data_y)\n",
    "    return np_data_x, np_data_y\n",
    "\n",
    "\n",
    "# # Use the Keras data generator to augment data.\n",
    "# def create_datagenerator(x_train, x_test, y_train, y_test):\n",
    "# #     train_datagen = ImageDataGenerator(\n",
    "# #         rescale=1. / 255,\n",
    "# #         rotation_range=0. / 180,\n",
    "# #         vertical_flip=True)\n",
    "#     pass\n",
    "    \n",
    "\n",
    "# #     test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#     train_generator = train_datagen.flow(x=x_train, y=y_train)\n",
    "#     validation_generator = test_datagen.flow(x=x_test, y=y_test)\n",
    "\n",
    "#     return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total output classes 36\n"
     ]
    }
   ],
   "source": [
    "print('total output classes',len(alphabet.keys()))\n",
    "batch_size = 32\n",
    "num_classes = len(alphabet.keys()) #62 for lite \n",
    "# num_classes = 26\n",
    "epochs = 200\n",
    "img_rows, img_cols = 64,64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading data.\n",
      "Data has been loaded.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=None and train_size=0.8, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-78f562f74a46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data has been loaded.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/umar_analyst/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2118\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2120\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/umar_analyst/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1803\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1804\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[0;32m-> 1805\u001b[0;31m                                                 train_size)\n\u001b[0m\u001b[1;32m   1806\u001b[0m         )\n\u001b[1;32m   1807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=None and train_size=0.8, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "print('Start loading data.')\n",
    "files, labels = load_chars74k_data()\n",
    "X, y = create_dataset(files, labels)\n",
    "print('Data has been loaded.')\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=2, train_size=0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "filepath=\"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 2, 2, 512)         14713536  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               524544    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 36)                9252      \n",
      "=================================================================\n",
      "Total params: 15,247,332\n",
      "Trainable params: 15,247,332\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelvgg=tf.keras.applications.vgg16.VGG16(include_top=False, weights=None, input_tensor=None, input_shape=(64, 64, 1))\n",
    "f0=(Flatten())\n",
    "d1=(Dense(256, activation='relu'))\n",
    "d2=(Dense(36, activation='softmax'))\n",
    "\n",
    "vggmodel = tf.keras.Sequential([\n",
    "  modelvgg,\n",
    "  f0,\n",
    "  d1,d2\n",
    "])\n",
    "vggmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train,y_train,\n",
    "                    steps_per_epoch=896 // batch_size,\n",
    "                    epochs=epochs,\n",
    "                    verbose=1,\n",
    "                    validation_data=(x_test,y_test),\n",
    "                    validation_steps=6000 // batch_size,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Model has been trained.')\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
